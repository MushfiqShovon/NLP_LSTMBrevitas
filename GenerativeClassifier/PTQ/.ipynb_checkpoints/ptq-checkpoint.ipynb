{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d9b1799-848f-46ab-a4f6-af89b29ff93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import math\n",
    "import logging\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import pandas as pd\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "104f7b77-ecf1-4709-8b4e-e214a82d7e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import Gen, GenQLSTM, GenQLSTM_2bit, GenQLSTM_1bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3496e90-4ad8-46e5-919d-2dd660f6a5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = torch.load(os.path.join('data', 'ag_news', 'data', 'traindata.v40000.l80.s5000'))\n",
    "traindata = data_dict['traindata']\n",
    "trainlabel = data_dict['trainlabel']\n",
    "validdata = data_dict['validdata']\n",
    "validlabel = data_dict['validlabel']\n",
    "testdata = data_dict['testdata']\n",
    "testlabel = data_dict['testlabel']\n",
    "vocab_size = data_dict['vocabsize']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f581672-3a31-42f0-bd3d-b5ce0da8ec74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "word_emb_dim = 100  # size of word embeddings\n",
    "label_emb_dim = 100  # size of label embeddings\n",
    "hid_dim = 100  # number of hidden units\n",
    "nlayers = 1  # number of lstm layers\n",
    "nclass = 4  # number of classes\n",
    "dropout = 0\n",
    "use_cuda = torch.cuda.is_available()\n",
    "tied = False\n",
    "use_bias = False\n",
    "concat_label = 'hidden'\n",
    "avg_loss = False\n",
    "one_hot = False\n",
    "bit_width=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0d914de-5558-42e9-8d0e-aa3f7a3b222e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e2b79eb-c68c-4fe0-83ce-7f9179a33d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Gen(vocab_size, word_emb_dim, label_emb_dim, hid_dim, nlayers, nclass, dropout, use_cuda, tied, use_bias, concat_label, avg_loss, one_hot, bit_width).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c11d774-0d58-4f01-93d3-cc55053cdff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss(reduce=False).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c4f2755-2382-4b9b-a380-ab4e55e7c4b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = 'ModelParameterLSTM_FP.pth'\n",
    "\n",
    "# Load the state dictionary from the file\n",
    "state_dict = torch.load(model_path)\n",
    "\n",
    "# Load the state dictionary into the model\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6737c08a-5b0c-4af0-92fc-ca5d165fd55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batches(data, label, batch_size, is_eval = False, nclass = 0):\n",
    "    d_l = list(zip(data, label))\n",
    "    random.shuffle(d_l)\n",
    "    data, label = zip(*d_l)\n",
    "    data, label = list(data), list(label)\n",
    "\n",
    "    for i in range(0, len(data), batch_size):\n",
    "        sentences = data[i:i + batch_size]\n",
    "        labels = label[i:i + batch_size]\n",
    "\n",
    "        s_l = zip(sentences, labels)\n",
    "        s_l = sorted(s_l, key = lambda l: len(l[0]), reverse=True)\n",
    "\n",
    "        sentences, labels = zip(*s_l)\n",
    "\n",
    "        sentences = list(sentences)\n",
    "        labels = list(labels)\n",
    "\n",
    "        # x_pred: predicted ground truth, padding in the end\n",
    "        # y_ext: extend label to the length of sentence length for concatnation\n",
    "        # seq_len: pred_seq_len = actual seq len - 1\n",
    "\n",
    "        y_ext = []\n",
    "        for idx, d in enumerate(sentences):\n",
    "            y_ext.append([labels[idx]] * (len(d) - 1))\n",
    "\n",
    "        if is_eval:\n",
    "            y_exts = []\n",
    "            for y_label in range(nclass):\n",
    "                y_ext = []\n",
    "                for d in sentences:\n",
    "                    y_ext.append(torch.LongTensor([y_label] * (len(d) - 1)))\n",
    "                y_exts.append(y_ext)\n",
    "\n",
    "            yield [torch.LongTensor(s) for s in sentences], y_exts, torch.LongTensor(labels)\n",
    "        else:\n",
    "            yield [torch.LongTensor(s) for s in sentences], \\\n",
    "                [torch.LongTensor(y) for y in y_ext], torch.LongTensor(labels)\n",
    "\n",
    "def evaluate(validdata, validlabel, model, criterion, args):\n",
    "    # Turn on evaluation mode which disables dropout.\n",
    "    model.eval()\n",
    "    total_loss = 0.\n",
    "    total_correct = 0.\n",
    "\n",
    "    cnt = 0\n",
    "    with torch.no_grad():\n",
    "        for sents, y_exts, labels in batches(validdata, validlabel, args.batch_size, True, args.nclass):\n",
    "            hidden = model.init_hidden(len(sents))\n",
    "\n",
    "            x = nn.utils.rnn.pack_sequence([s[:-1] for s in sents])\n",
    "            x_pred = nn.utils.rnn.pack_sequence([s[1:] for s in sents])\n",
    "\n",
    "            # p_y = torch.FloatTensor([0.071] * len(seq_len))\n",
    "\n",
    "            losses = []\n",
    "            for y_ext in y_exts:\n",
    "                y_ext = nn.utils.rnn.pack_sequence(y_ext)\n",
    "\n",
    "                if args.device.type == 'cuda':\n",
    "                    x, y_ext, x_pred, labels = x.cuda(), y_ext.cuda(), x_pred.cuda(), labels.cuda()\n",
    "\n",
    "                # output (batch_size, )\n",
    "                hidden = model.init_hidden(len(sents))\n",
    "                #if args.device.type == 'cuda':\n",
    "                #    hidden = hidden.cuda()\n",
    "                #    model=model.cuda()\n",
    "                loss = model(x, x_pred, y_ext, hidden, criterion, True)\n",
    "                losses.append(loss)\n",
    "\n",
    "            losses = torch.cat(losses, dim=0).view(-1, len(sents))\n",
    "            prediction = torch.argmin(losses, dim=0)\n",
    "\n",
    "            num_correct = (prediction == labels).float().sum()\n",
    "\n",
    "            total_loss += torch.sum(torch.min(losses, dim=0)[0]).item()\n",
    "            total_correct += num_correct.item()\n",
    "            cnt += 1\n",
    "\n",
    "    return total_loss / cnt, total_correct / len(validlabel) * 100.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0fdaa847-bf10-4db7-86a5-a824696708f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(bit_width, model, save_dir):\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    filename = os.path.join(save_dir, f'ModelParameter_{bit_width}.pth')\n",
    "    torch.save(model.state_dict(), filename)\n",
    "    logging.info(f\"Model saved to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7653d0c3-0b09-47ed-af63-3d9f270a4aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class var:\n",
    "    batch_size=32\n",
    "    nclass = len(open(os.path.join('data', 'ag_news', 'classes.txt'), 'r').readlines())\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "var=var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db1b0729-6be0-4582-8762-8c539aa233dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "| Test | test loss  7170.726817924436  | test acc  88.4342105263158\n",
      "=========================================================================================\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_start_time = time.time()\n",
    "test_loss, test_acc = evaluate(testdata, testlabel, model, criterion, var)\n",
    "test_time=time.time()-test_start_time\n",
    "print('=' * 89)\n",
    "print('| Test | test loss ', test_loss, ' | test acc ', test_acc)\n",
    "print('=' * 89)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a2c60cf-a73b-49f3-a3bd-6115cbc40837",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantized_model = GenQLSTM(vocab_size, word_emb_dim, label_emb_dim, hid_dim, nlayers, nclass, dropout, use_cuda, tied, use_bias, concat_label, avg_loss, one_hot, bit_width).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82fbd368-72af-4071-a8bf-29c456f9bc13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder.weight\n",
      "label_encoder.weight\n",
      "rnn.layers.0.0.cell.output_quant.fused_activation_quant_proxy.tensor_quant.scaling_impl.value\n",
      "rnn.layers.0.0.cell.cell_state_quant.fused_activation_quant_proxy.tensor_quant.scaling_impl.value\n",
      "rnn.layers.0.0.cell.input_acc_quant.fused_activation_quant_proxy.tensor_quant.scaling_impl.value\n",
      "rnn.layers.0.0.cell.forget_acc_quant.fused_activation_quant_proxy.tensor_quant.scaling_impl.value\n",
      "rnn.layers.0.0.cell.cell_acc_quant.fused_activation_quant_proxy.tensor_quant.scaling_impl.value\n",
      "rnn.layers.0.0.cell.output_acc_quant.fused_activation_quant_proxy.tensor_quant.scaling_impl.value\n",
      "rnn.layers.0.0.cell.input_sigmoid_quant.fused_activation_quant_proxy.tensor_quant.scaling_impl.value\n",
      "rnn.layers.0.0.cell.forget_sigmoid_quant.fused_activation_quant_proxy.tensor_quant.scaling_impl.value\n",
      "rnn.layers.0.0.cell.cell_tanh_quant.fused_activation_quant_proxy.tensor_quant.scaling_impl.value\n",
      "rnn.layers.0.0.cell.output_sigmoid_quant.fused_activation_quant_proxy.tensor_quant.scaling_impl.value\n",
      "rnn.layers.0.0.cell.hidden_state_tanh_quant.fused_activation_quant_proxy.tensor_quant.scaling_impl.value\n",
      "rnn.layers.0.0.input_gate_params.bias\n",
      "rnn.layers.0.0.input_gate_params.input_weight.weight\n",
      "rnn.layers.0.0.input_gate_params.input_weight.weight_quant.tensor_quant.scaling_impl.parameter_list_stats.extra_tracked_params_list.0.parameter\n",
      "rnn.layers.0.0.forget_gate_params.bias\n",
      "rnn.layers.0.0.forget_gate_params.input_weight.weight\n",
      "rnn.layers.0.0.forget_gate_params.input_weight.weight_quant.tensor_quant.scaling_impl.parameter_list_stats.extra_tracked_params_list.0.parameter\n",
      "rnn.layers.0.0.cell_gate_params.bias\n",
      "rnn.layers.0.0.cell_gate_params.input_weight.weight\n",
      "rnn.layers.0.0.cell_gate_params.input_weight.weight_quant.tensor_quant.scaling_impl.parameter_list_stats.extra_tracked_params_list.0.parameter\n",
      "rnn.layers.0.0.output_gate_params.bias\n",
      "rnn.layers.0.0.output_gate_params.input_weight.weight\n",
      "rnn.layers.0.0.output_gate_params.input_weight.weight_quant.tensor_quant.scaling_impl.parameter_list_stats.extra_tracked_params_list.0.parameter\n",
      "decoder.weight\n"
     ]
    }
   ],
   "source": [
    "for name, param in quantized_model.named_parameters():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f288dbbf-b82b-438b-9ab6-dd78f08c1820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure that the hidden_dim is defined based on your model configuration\n",
    "hidden_dim = hid_dim\n",
    "\n",
    "# Transfer parameters from pretrained model to quantized model\n",
    "quantized_model.encoder.weight.data = model.encoder.weight.data\n",
    "quantized_model.label_encoder.weight.data = model.label_encoder.weight.data\n",
    "\n",
    "# LSTM weights and biases\n",
    "quantized_model.rnn.layers[0][0].input_gate_params.input_weight.weight.data = model.rnn.weight_ih_l0[:hidden_dim, :].data\n",
    "quantized_model.rnn.layers[0][0].forget_gate_params.input_weight.weight.data = model.rnn.weight_ih_l0[hidden_dim:2*hidden_dim, :].data\n",
    "quantized_model.rnn.layers[0][0].cell_gate_params.input_weight.weight.data = model.rnn.weight_ih_l0[2*hidden_dim:3*hidden_dim, :].data\n",
    "quantized_model.rnn.layers[0][0].output_gate_params.input_weight.weight.data = model.rnn.weight_ih_l0[3*hidden_dim:, :].data\n",
    "\n",
    "quantized_model.rnn.layers[0][0].input_gate_params.hidden_weight.weight.data = model.rnn.weight_hh_l0[:hidden_dim, :].data\n",
    "quantized_model.rnn.layers[0][0].forget_gate_params.hidden_weight.weight.data = model.rnn.weight_hh_l0[hidden_dim:2*hidden_dim, :].data\n",
    "quantized_model.rnn.layers[0][0].cell_gate_params.hidden_weight.weight.data = model.rnn.weight_hh_l0[2*hidden_dim:3*hidden_dim, :].data\n",
    "quantized_model.rnn.layers[0][0].output_gate_params.hidden_weight.weight.data = model.rnn.weight_hh_l0[3*hidden_dim:, :].data\n",
    "\n",
    "quantized_model.rnn.layers[0][0].input_gate_params.bias.data = model.rnn.bias_ih_l0[:hidden_dim].data + model.rnn.bias_hh_l0[:hidden_dim].data\n",
    "quantized_model.rnn.layers[0][0].forget_gate_params.bias.data = model.rnn.bias_ih_l0[hidden_dim:2*hidden_dim].data + model.rnn.bias_hh_l0[hidden_dim:2*hidden_dim].data\n",
    "quantized_model.rnn.layers[0][0].cell_gate_params.bias.data = model.rnn.bias_ih_l0[2*hidden_dim:3*hidden_dim].data + model.rnn.bias_hh_l0[2*hidden_dim:3*hidden_dim].data\n",
    "quantized_model.rnn.layers[0][0].output_gate_params.bias.data = model.rnn.bias_ih_l0[3*hidden_dim:].data + model.rnn.bias_hh_l0[3*hidden_dim:].data\n",
    "\n",
    "quantized_model.decoder.weight.data = model.decoder.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f1ef3357-fe6b-4711-b02c-0247b631b429",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir=f'./ModelParameter/FULL_Quantized/{bit_width}bit/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3dee2ff7-ca3a-4d36-ac34-2619a5d225ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fed597ba-e702-4763-b1ea-632845113134",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    # Sort batch by sequence length in descending order\n",
    "    batch.sort(key=lambda x: len(x[0]), reverse=True)\n",
    "    \n",
    "    sequences, labels = zip(*batch)\n",
    "    \n",
    "    # Pad sequences\n",
    "    sequences_padded = pad_sequence([torch.LongTensor(seq) for seq in sequences], batch_first=True, padding_value=0)\n",
    "    \n",
    "    # Create a tensor for labels\n",
    "    labels_tensor = torch.LongTensor(labels)\n",
    "    \n",
    "    return sequences_padded, labels_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4dfedbcf-75c1-4c3c-90db-dfcc39f3a0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def get_calibration_dataloader(traindata, trainlabel, batch_size):\n",
    "    dataset = TextDataset(traindata, trainlabel)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "    return dataloader\n",
    "\n",
    "# Creating DataLoader for calibration data\n",
    "calibration_dataloader = get_calibration_dataloader(traindata, trainlabel, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d79f0573-3c0c-4606-8600-8d889d84840d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibrate_model(model, dataloader, device):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            hidden = model.init_hidden(inputs.size(0))\n",
    "            \n",
    "            # Create y_ext manually to match input sequences\n",
    "            y_ext = torch.zeros_like(inputs)\n",
    "            for i, label in enumerate(labels):\n",
    "                y_ext[i, :] = label\n",
    "\n",
    "            # Shift x_pred to match the required prediction\n",
    "            x_pred = torch.zeros_like(inputs)\n",
    "            x_pred[:, :-1] = inputs[:, 1:]\n",
    "\n",
    "            _ = model(inputs, x_pred, y_ext, hidden, criterion=None, is_infer=True, cal=True)  # No criterion needed\n",
    "    print(\"Calibration complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d4109436-3257-4084-b9f7-0b181a9d6286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward pass count: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/torch/_tensor.py:1271: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at ../c10/core/TensorImpl.h:1788.)\n",
      "  return super().rename(names)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward pass count: 2\n",
      "Forward pass count: 3\n",
      "Forward pass count: 4\n",
      "Forward pass count: 5\n",
      "Forward pass count: 6\n",
      "Forward pass count: 7\n",
      "Forward pass count: 8\n",
      "Forward pass count: 9\n",
      "Forward pass count: 10\n",
      "Forward pass count: 11\n",
      "Forward pass count: 12\n",
      "Forward pass count: 13\n",
      "Forward pass count: 14\n",
      "Forward pass count: 15\n",
      "Forward pass count: 16\n",
      "Forward pass count: 17\n",
      "Forward pass count: 18\n",
      "Forward pass count: 19\n",
      "Forward pass count: 20\n",
      "Forward pass count: 21\n",
      "Forward pass count: 22\n",
      "Forward pass count: 23\n",
      "Forward pass count: 24\n",
      "Forward pass count: 25\n",
      "Forward pass count: 26\n",
      "Forward pass count: 27\n",
      "Forward pass count: 28\n",
      "Forward pass count: 29\n",
      "Forward pass count: 30\n",
      "Forward pass count: 31\n",
      "Forward pass count: 32\n",
      "Forward pass count: 33\n",
      "Forward pass count: 34\n",
      "Forward pass count: 35\n",
      "Forward pass count: 36\n",
      "Forward pass count: 37\n",
      "Forward pass count: 38\n",
      "Forward pass count: 39\n",
      "Forward pass count: 40\n",
      "Forward pass count: 41\n",
      "Forward pass count: 42\n",
      "Forward pass count: 43\n",
      "Forward pass count: 44\n",
      "Forward pass count: 45\n",
      "Forward pass count: 46\n",
      "Forward pass count: 47\n",
      "Forward pass count: 48\n",
      "Forward pass count: 49\n",
      "Forward pass count: 50\n",
      "Forward pass count: 51\n",
      "Forward pass count: 52\n",
      "Forward pass count: 53\n",
      "Forward pass count: 54\n",
      "Forward pass count: 55\n",
      "Forward pass count: 56\n",
      "Forward pass count: 57\n",
      "Forward pass count: 58\n",
      "Forward pass count: 59\n",
      "Forward pass count: 60\n",
      "Forward pass count: 61\n",
      "Forward pass count: 62\n",
      "Forward pass count: 63\n",
      "Forward pass count: 64\n",
      "Forward pass count: 65\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcalibrate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquantized_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcalibration_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[20], line 17\u001b[0m, in \u001b[0;36mcalibrate_model\u001b[0;34m(model, dataloader, device)\u001b[0m\n\u001b[1;32m     14\u001b[0m         x_pred \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros_like(inputs)\n\u001b[1;32m     15\u001b[0m         x_pred[:, :\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m inputs[:, \u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m---> 17\u001b[0m         _ \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_ext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_infer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# No criterion needed\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCalibration complete.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/zxy-volume-ceph/mushfiqShovon/Gen-model/PTQ/models.py:201\u001b[0m, in \u001b[0;36mGenQLSTM.forward\u001b[0;34m(self, x, x_pred, y_ext, hidden, criterion, is_infer)\u001b[0m\n\u001b[1;32m    196\u001b[0m embedded_sents \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mrnn\u001b[38;5;241m.\u001b[39mpad_sequence(embedded_sents, batch_first\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m#print(\"Embedded Sents Size after packing:\", type(embedded_sents), embedded_sents.size())\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m#print(\"hidden size:\", hidden.size())\u001b[39;00m\n\u001b[0;32m--> 201\u001b[0m output, hidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43membedded_sents\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Adjusted to handle RNN output\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;66;03m#print(\"output of rnn:\", output.data.size())\u001b[39;00m\n\u001b[1;32m    205\u001b[0m first_part \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mdata[:, \u001b[38;5;241m0\u001b[39m, :]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/brevitas/nn/quant_rnn.py:979\u001b[0m, in \u001b[0;36mQuantLSTM.forward\u001b[0;34m(self, inp, hx, cx)\u001b[0m\n\u001b[1;32m    977\u001b[0m layer_hidden_state \u001b[38;5;241m=\u001b[39m hx[\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m l \u001b[38;5;241m+\u001b[39m d] \u001b[38;5;28;01mif\u001b[39;00m hx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m hx\n\u001b[1;32m    978\u001b[0m layer_cell_state \u001b[38;5;241m=\u001b[39m cx[\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m l \u001b[38;5;241m+\u001b[39m d] \u001b[38;5;28;01mif\u001b[39;00m cx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m cx\n\u001b[0;32m--> 979\u001b[0m out, out_hidden_state, out_cell_state \u001b[38;5;241m=\u001b[39m \u001b[43mdirection\u001b[49m\u001b[43m(\u001b[49m\u001b[43minp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_hidden_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_cell_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    980\u001b[0m dir_outputs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [out]\n\u001b[1;32m    981\u001b[0m dir_hidden_states \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [out_hidden_state]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/brevitas/nn/quant_rnn.py:710\u001b[0m, in \u001b[0;36m_QuantLSTMLayer.forward\u001b[0;34m(self, inp, hidden_state, cell_state)\u001b[0m\n\u001b[1;32m    708\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    709\u001b[0m     cell \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcell\n\u001b[0;32m--> 710\u001b[0m quant_outputs, quant_hidden_state, quant_cell_state \u001b[38;5;241m=\u001b[39m \u001b[43mcell\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    711\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquant_input\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    712\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquant_hidden_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquant_cell_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    714\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquant_weight_ii\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquant_weight_ii\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    715\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquant_weight_if\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquant_weight_if\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    716\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquant_weight_ic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquant_weight_ic\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    717\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquant_weight_io\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquant_weight_io\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    718\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquant_weight_hi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquant_weight_hi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    719\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquant_weight_hf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquant_weight_hf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquant_weight_hc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquant_weight_hc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquant_weight_ho\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquant_weight_ho\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquant_bias_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquant_bias_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    723\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquant_bias_forget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquant_bias_forget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    724\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquant_bias_cell\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquant_bias_cell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    725\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquant_bias_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquant_bias_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    726\u001b[0m quant_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpack_quant_outputs(quant_outputs)\n\u001b[1;32m    727\u001b[0m quant_hidden_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpack_quant_state(quant_hidden_state, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcell\u001b[38;5;241m.\u001b[39moutput_quant)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/brevitas/nn/quant_rnn.py:299\u001b[0m, in \u001b[0;36m_QuantLSTMCell.forward\u001b[0;34m(self, quant_input, quant_hidden_state, quant_cell_state, quant_weight_ii, quant_weight_if, quant_weight_ic, quant_weight_io, quant_weight_hi, quant_weight_hf, quant_weight_hc, quant_weight_ho, quant_bias_input, quant_bias_forget, quant_bias_cell, quant_bias_output)\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(end):\n\u001b[1;32m    298\u001b[0m     quant_input \u001b[38;5;241m=\u001b[39m quant_inputs[index]\n\u001b[0;32m--> 299\u001b[0m     quant_hidden_state_tuple, quant_cell_state_tuple \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_iter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquant_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquant_hidden_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquant_cell_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquant_weight_ii\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquant_weight_if\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquant_weight_ic\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquant_weight_io\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquant_weight_hi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquant_weight_hf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquant_weight_hc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquant_weight_ho\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquant_bias_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquant_bias_forget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquant_bias_cell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquant_bias_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    315\u001b[0m     index \u001b[38;5;241m=\u001b[39m index \u001b[38;5;241m+\u001b[39m step\n\u001b[1;32m    316\u001b[0m     quant_hidden_states \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [quant_hidden_state_tuple]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/brevitas/nn/quant_rnn.py:235\u001b[0m, in \u001b[0;36m_QuantLSTMCell.forward_iter\u001b[0;34m(self, quant_input, quant_hidden_state, quant_cell_state, quant_weight_ii, quant_weight_if, quant_weight_ic, quant_weight_io, quant_weight_hi, quant_weight_hf, quant_weight_hc, quant_weight_ho, quant_bias_input, quant_bias_forget, quant_bias_cell, quant_bias_output)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward_iter\u001b[39m(\n\u001b[1;32m    217\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    218\u001b[0m         quant_input: Tensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    232\u001b[0m         quant_bias_output: Tensor):\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;66;03m# Input gate\u001b[39;00m\n\u001b[1;32m    234\u001b[0m     quant_ii_gate \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mlinear(quant_input, quant_weight_ii)\n\u001b[0;32m--> 235\u001b[0m     quant_hi_gate \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquant_hidden_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquant_weight_hi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    236\u001b[0m     quant_input_gate \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_acc_quant(quant_ii_gate \u001b[38;5;241m+\u001b[39m quant_hi_gate \u001b[38;5;241m+\u001b[39m quant_bias_input)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    237\u001b[0m     quant_input_gate \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_sigmoid_quant(quant_input_gate)[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "calibrate_model(quantized_model, calibration_dataloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3dc2cb0d-7110-436b-a2a2-d78284f6a4db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward pass count: 66\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m quantized_model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m      2\u001b[0m test_start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m----> 3\u001b[0m test_loss, test_acc \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtestdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtestlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquantized_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvar\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m test_time\u001b[38;5;241m=\u001b[39mtime\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;241m-\u001b[39mtest_start_time\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m89\u001b[39m)\n",
      "Cell \u001b[0;32mIn[9], line 68\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(validdata, validlabel, model, criterion, args)\u001b[0m\n\u001b[1;32m     64\u001b[0m     hidden \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39minit_hidden(\u001b[38;5;28mlen\u001b[39m(sents))\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;66;03m#if args.device.type == 'cuda':\u001b[39;00m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;66;03m#    hidden = hidden.cuda()\u001b[39;00m\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;66;03m#    model=model.cuda()\u001b[39;00m\n\u001b[0;32m---> 68\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_ext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m     losses\u001b[38;5;241m.\u001b[39mappend(loss)\n\u001b[1;32m     71\u001b[0m losses \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(losses, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(sents))\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/zxy-volume-ceph/mushfiqShovon/Gen-model/PTQ/models.py:214\u001b[0m, in \u001b[0;36mGenQLSTM.forward\u001b[0;34m(self, x, x_pred, y_ext, hidden, criterion, is_infer)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;66;03m#result = result.view(-1, 100)\u001b[39;00m\n\u001b[1;32m    211\u001b[0m \u001b[38;5;66;03m#print(\"Result Size:\", result.size())\u001b[39;00m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconcat_label \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 214\u001b[0m     embedded_label \u001b[38;5;241m=\u001b[39m \u001b[43membedded_label\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    215\u001b[0m     hidden_data \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((result, embedded_label), \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for tensor of dimension 2"
     ]
    }
   ],
   "source": [
    "quantized_model.eval()\n",
    "test_start_time = time.time()\n",
    "test_loss, test_acc = evaluate(testdata, testlabel, quantized_model, criterion, var)\n",
    "test_time=time.time()-test_start_time\n",
    "print('=' * 89)\n",
    "print('| Test | test loss ', test_loss, ' | test acc ', test_acc)\n",
    "print('=' * 89)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ca3b8e-f359-4fa8-a1a2-7f4d70e8bc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(0, quantized_model, model_dir)\n",
    "accuracies = []\n",
    "accuracies.append({'Epoch': 'Test', 'Validation Accuracy': test_acc, 'Epoch Time': test_time})\n",
    "df_accuracies = pd.DataFrame(accuracies)\n",
    "accuracy_save_path = model_dir + f'accuracies_{bit_width}bit.csv'\n",
    "df_accuracies.to_csv(accuracy_save_path, index=False)\n",
    "print(f'Accuracies saved at \"{accuracy_save_path}\"')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
