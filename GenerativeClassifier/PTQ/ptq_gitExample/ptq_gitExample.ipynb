{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1eef634d-373a-42c8-8bbc-7f7ebe110f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import math\n",
    "import logging\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import pandas as pd\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36d301ed-f194-46d2-8162-72ee022099c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import Gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74d53298-bc06-4198-b98e-c084839c136c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "word_emb_dim = 100  # size of word embeddings\n",
    "label_emb_dim = 100  # size of label embeddings\n",
    "hid_dim = 100  # number of hidden units\n",
    "nlayers = 1  # number of lstm layers\n",
    "nclass = 4  # number of classes\n",
    "dropout = 0\n",
    "use_cuda = torch.cuda.is_available()\n",
    "tied = False\n",
    "use_bias = False\n",
    "concat_label = 'hidden'\n",
    "avg_loss = False\n",
    "one_hot = False\n",
    "bit_width=8\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d87d9a4b-e772-4e0a-8a5b-16389480e5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = torch.load(os.path.join('../data', 'ag_news', 'data', 'traindata.v40000.l80.s5000'))\n",
    "traindata = data_dict['traindata']\n",
    "trainlabel = data_dict['trainlabel']\n",
    "validdata = data_dict['validdata']\n",
    "validlabel = data_dict['validlabel']\n",
    "testdata = data_dict['testdata']\n",
    "testlabel = data_dict['testlabel']\n",
    "vocab_size = data_dict['vocabsize']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec557b22-6f49-4135-a09c-c9861ad50c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Gen(vocab_size, word_emb_dim, label_emb_dim, hid_dim, nlayers, nclass, dropout, use_cuda, tied, use_bias, concat_label, avg_loss, one_hot, bit_width).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "139faba0-7298-4009-9866-b75f692a2145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = '../ModelParameterLSTM_FP.pth'\n",
    "\n",
    "# Load the state dictionary from the file\n",
    "state_dict = torch.load(model_path)\n",
    "\n",
    "# Load the state dictionary into the model\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62a66cc0-79ad-4db5-a6e6-0bdbf508d86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.parallel\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "import torchvision\n",
    "\n",
    "from brevitas.export import export_onnx_qcdq\n",
    "from brevitas.export import export_torch_qcdq\n",
    "from brevitas.graph.equalize import activation_equalization_mode\n",
    "from brevitas.graph.quantize import preprocess_for_quantize\n",
    "from brevitas.graph.target.flexml import preprocess_for_flexml_quantize\n",
    "from brevitas_examples.imagenet_classification.ptq.ptq_common import apply_act_equalization\n",
    "from brevitas_examples.imagenet_classification.ptq.ptq_common import apply_bias_correction\n",
    "from brevitas_examples.imagenet_classification.ptq.ptq_common import apply_gpfq\n",
    "from brevitas_examples.imagenet_classification.ptq.ptq_common import apply_gptq\n",
    "from brevitas_examples.imagenet_classification.ptq.ptq_common import apply_learned_round_learning\n",
    "from brevitas_examples.imagenet_classification.ptq.ptq_common import calibrate\n",
    "from brevitas_examples.imagenet_classification.ptq.ptq_common import calibrate_bn\n",
    "from brevitas_examples.imagenet_classification.ptq.ptq_common import quantize_model\n",
    "from brevitas_examples.imagenet_classification.ptq.utils import add_bool_arg\n",
    "from brevitas_examples.imagenet_classification.ptq.utils import get_model_config\n",
    "from brevitas_examples.imagenet_classification.ptq.utils import get_torchvision_model\n",
    "from brevitas_examples.imagenet_classification.utils import generate_dataloader\n",
    "from brevitas_examples.imagenet_classification.utils import SEED\n",
    "from brevitas_examples.imagenet_classification.utils import validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d66a08e-a3db-4e00-aa17-3d86894a03ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = get_model_config(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fc6efd0c-2d05-4689-a292-8b02252e252a",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Gen' object has no attribute 'graph'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m quant_model \u001b[38;5;241m=\u001b[39m \u001b[43mquantize_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfx\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# or 'layerwise' based on your preference\u001b[39;49;00m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_bit_width\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mact_bit_width\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbias_bit_width\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_quant_granularity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mper_tensor\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mact_quant_percentile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m99.999\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mact_quant_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msym\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscale_factor_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfloat_scale\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquant_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mint\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# or 'cuda' if using GPU\u001b[39;49;00m\n\u001b[1;32m     13\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/brevitas_examples/imagenet_classification/ptq/ptq_common.py:254\u001b[0m, in \u001b[0;36mquantize_model\u001b[0;34m(model, backend, weight_bit_width, act_bit_width, bias_bit_width, weight_quant_granularity, act_quant_percentile, act_quant_type, scale_factor_type, quant_format, layerwise_first_last_bit_width, layerwise_first_last_mantissa_bit_width, layerwise_first_last_exponent_bit_width, weight_mantissa_bit_width, weight_exponent_bit_width, act_mantissa_bit_width, act_exponent_bit_width, weight_narrow_range, weight_param_method, act_param_method, weight_quant_type, act_quant_granularity, uint_sym_act_for_unsigned_values, dtype, device)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;66;03m# Layerwise requires only the compute layer mapping\u001b[39;00m\n\u001b[1;32m    252\u001b[0m     quantize_kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcompute_layer_map\u001b[39m\u001b[38;5;124m'\u001b[39m: quant_layerwise_layer_map}\n\u001b[0;32m--> 254\u001b[0m quant_model \u001b[38;5;241m=\u001b[39m \u001b[43mquantize_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mquantize_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m quant_model\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/brevitas/graph/quantize.py:312\u001b[0m, in \u001b[0;36mquantize\u001b[0;34m(graph_model, quant_identity_map, compute_layer_map, quant_act_map, unsigned_act_tuple, requantize_layer_handler_output)\u001b[0m\n\u001b[1;32m    310\u001b[0m training_state \u001b[38;5;241m=\u001b[39m graph_model\u001b[38;5;241m.\u001b[39mtraining\n\u001b[1;32m    311\u001b[0m graph_model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m--> 312\u001b[0m graph_model \u001b[38;5;241m=\u001b[39m \u001b[43minp_placeholder_handler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgraph_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_quantizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquant_identity_map\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msigned\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    314\u001b[0m graph_model \u001b[38;5;241m=\u001b[39m act_handler(graph_model, layer_map\u001b[38;5;241m=\u001b[39mquant_act_map)\n\u001b[1;32m    315\u001b[0m graph_model \u001b[38;5;241m=\u001b[39m add_output_quant_handler(\n\u001b[1;32m    316\u001b[0m     graph_model, quant_identity_map, quant_act_map, unsigned_act_tuple)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/brevitas/graph/quantize_impl.py:63\u001b[0m, in \u001b[0;36minp_placeholder_handler\u001b[0;34m(model, input_quantizer)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m input_quantizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n\u001b[0;32m---> 63\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgraph\u001b[49m\u001b[38;5;241m.\u001b[39mnodes:\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m node\u001b[38;5;241m.\u001b[39mop \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplaceholder\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     65\u001b[0m         act_quant, kwargs_act_quant \u001b[38;5;241m=\u001b[39m input_quantizer\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1614\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1612\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1613\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1614\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1615\u001b[0m     \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, name))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Gen' object has no attribute 'graph'"
     ]
    }
   ],
   "source": [
    "quant_model = quantize_model(\n",
    "    model,\n",
    "    backend='fx',  # or 'layerwise' based on your preference\n",
    "    weight_bit_width=8,\n",
    "    act_bit_width=8,\n",
    "    bias_bit_width=32,\n",
    "    weight_quant_granularity='per_tensor',\n",
    "    act_quant_percentile=99.999,\n",
    "    act_quant_type='sym',\n",
    "    scale_factor_type='float_scale',\n",
    "    quant_format='int',\n",
    "    device='cpu'  # or 'cuda' if using GPU\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf09b4a6-8e58-4c07-912e-9eb03a667382",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
